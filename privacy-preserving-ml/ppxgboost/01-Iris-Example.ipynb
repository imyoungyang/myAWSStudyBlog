{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0006eb41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'privacy-preserving-xgboost-inference' already exists and is not an empty directory.\n",
      "/home/ec2-user/SageMaker/myAWSStudyBlog/privacy-preserving-ml/ppxgboost/privacy-preserving-xgboost-inference\n",
      "Obtaining file:///home/ec2-user/SageMaker/myAWSStudyBlog/privacy-preserving-ml/ppxgboost/privacy-preserving-xgboost-inference (from -r requirements.txt (line 8))\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas==0.25.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.25.3)\n",
      "Requirement already satisfied: phe==1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: xgboost==0.90 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.90)\n",
      "Requirement already satisfied: numpy==1.17.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.17.4)\n",
      "Requirement already satisfied: scikit-learn==0.21.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.21.3)\n",
      "Requirement already satisfied: flask==1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: pytest==5.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (5.1.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost==0.90->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn==0.21.3->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask==1.1.1->-r requirements.txt (line 6)) (2.11.3)\n",
      "Requirement already satisfied: click>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask==1.1.1->-r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask==1.1.1->-r requirements.txt (line 6)) (2.0.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask==1.1.1->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (0.2.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (3.7.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (20.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (0.13.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (21.3)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (8.7.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (1.10.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest==5.1.2->-r requirements.txt (line 7)) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest==5.1.2->-r requirements.txt (line 7)) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Jinja2>=2.10.1->flask==1.1.1->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas==0.25.3->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Werkzeug>=0.15->flask==1.1.1->-r requirements.txt (line 6)) (0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->pytest==5.1.2->-r requirements.txt (line 7)) (2.4.7)\n",
      "Installing collected packages: ppxgboost\n",
      "  Attempting uninstall: ppxgboost\n",
      "    Found existing installation: ppxgboost 0.0.1\n",
      "    Uninstalling ppxgboost-0.0.1:\n",
      "      Successfully uninstalled ppxgboost-0.0.1\n",
      "  Running setup.py develop for ppxgboost\n",
      "Successfully installed ppxgboost-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/awslabs/privacy-preserving-xgboost-inference.git\n",
    "%cd privacy-preserving-xgboost-inference\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999b678",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f716f4",
   "metadata": {},
   "source": [
    "( Run <code>jupyter notebook</code> under the project directory )\n",
    "\n",
    "# XGBoost for Iris Dataset\n",
    "\n",
    "We use this example to demenstrate how to use ppxgboost for encypting an xgboost model for multi-class\n",
    " prediction. We directly use the iris data from Sklearn, but one\n",
    " can go to https://archive.ics.uci.edu/ml/datasets/iris to download the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f2338c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('third-party')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from secrets import token_bytes\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ppxgboost import BoosterParser as boostparser\n",
    "from ppxgboost import PPBooster as ppbooster\n",
    "from ppxgboost.PPBooster import MetaData\n",
    "from ppxgboost.PPKey import PPBoostKey\n",
    "from ope.pyope.ope import OPE\n",
    "from ppxgboost import PaillierAPI as paillier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8faf5059",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Pre-assign the column name first.\n",
    "# the default feature name from the xgboost -- iris have 4 columns\n",
    "feature_names = ['f0', 'f1', 'f2', 'f3']\n",
    "X = pd.DataFrame(X, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1b575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f0   f1   f2   f3\n",
       "0  5.1  3.5  1.4  0.2\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2\n",
       "3  4.6  3.1  1.5  0.2\n",
       "4  5.0  3.6  1.4  0.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d8920f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323d7e54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "test_input_vector = pd.DataFrame(X_test, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ae1b95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=6, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first dump and pickled the model in the file directory.\n",
    "# total number of tree = total_estimators * number_labels\n",
    "# e.g. for the imported iris dataset, the number of classes is 3.\n",
    "\n",
    "# Just provide estimator number for testing purposes.\n",
    "total_estimaters = 6\n",
    "model = xgb.XGBClassifier(n_estimators=total_estimaters, objective='multi:softmax')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "820b4fb4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of classes -- i.e. 3 from iris dataset\n",
    "# The classes as array can be get by calling model.classes_\n",
    "num_classes = model.n_classes_\n",
    "\n",
    "# Booster Parser will parse the tree\n",
    "#  (add fake metadata here as this testing only test the model correctness)\n",
    "min_max = {'min': 0, 'max': 100}\n",
    "meta_min_max = MetaData(min_max)\n",
    "p_trees, features, min_max = boostparser.model_to_trees(model.get_booster(), min_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b5eca4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Encryption Preparation for XGBoost Model\n",
    "1). Set up some metadata information for the dataset.\n",
    "2). Set up the encryption materials\n",
    "3). Encrypt the model\n",
    "4). Encrypt the query\n",
    "5). Perform the prediction \n",
    "6). Decrypt the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7022aea4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ##################################################################################\n",
    "# # The folowing is to compute the scores based on the OPE processed decision tree #\n",
    "# ##################################################################################\n",
    "# # Set up encryption materials.\n",
    "# # token bytes calls the os.urandom().\n",
    "prf_key = token_bytes(16)\n",
    "OPE_key = token_bytes(16)\n",
    "encrypter = OPE(OPE_key)\n",
    "public_key, private_key = paillier.he_key_gen()\n",
    "pp_boostKey = PPBoostKey(public_key, prf_key, encrypter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6daf4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. process the tree into ope_enc_tree\n",
    "enc_trees = ppbooster.enc_xgboost_model(pp_boostKey, p_trees, meta_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a072247",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Encrypts the input vector for prediction (using prf_key_hash and ope-encrypter) based on the feature set.\n",
    "ppbooster.enc_input_vector(prf_key, encrypter, features, test_input_vector, meta_min_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdf04a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that: The prediction on the server side is done differently from the log:binary. This is because\n",
    "the server needs to perofrm the softmax aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170e2eb3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3. OPE evaluation based on OPE encrypted values in the tree nodes.\n",
    "enc_predictions = ppbooster.predict_multiclass(enc_trees, num_classes, test_input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b051cf2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Client decryption.\n",
    "result = ppbooster.client_decrypt_prediction_multiclass(private_key, enc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9296100",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "real_y = model.predict(X_test)\n",
    "assert np.array_equal(result, real_y)\n",
    "print(\"success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd4e80",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Remove the ppxgboost folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c78e2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/myAWSStudyBlog/privacy-preserving-ml/ppxgboost\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!rm -rf privacy-preserving-xgboost-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89372327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

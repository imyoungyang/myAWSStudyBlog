{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e00920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'privacy-preserving-xgboost-inference' already exists and is not an empty directory.\n",
      "/home/ec2-user/SageMaker/myAWSStudyBlog/privacy-preserving-ml/ppxgboost/privacy-preserving-xgboost-inference\n",
      "Obtaining file:///home/ec2-user/SageMaker/myAWSStudyBlog/privacy-preserving-ml/ppxgboost/privacy-preserving-xgboost-inference (from -r requirements.txt (line 8))\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas==0.25.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.25.3)\n",
      "Requirement already satisfied: phe==1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: xgboost==0.90 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.90)\n",
      "Requirement already satisfied: numpy==1.17.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (1.17.4)\n",
      "Requirement already satisfied: scikit-learn==0.21.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.21.3)\n",
      "Requirement already satisfied: flask==1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: pytest==5.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (5.1.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost==0.90->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn==0.21.3->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask==1.1.1->-r requirements.txt (line 6)) (2.11.3)\n",
      "Requirement already satisfied: click>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask==1.1.1->-r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask==1.1.1->-r requirements.txt (line 6)) (2.0.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from flask==1.1.1->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (0.13.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (21.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (20.3.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (0.2.5)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (1.10.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (3.7.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest==5.1.2->-r requirements.txt (line 7)) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest==5.1.2->-r requirements.txt (line 7)) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest==5.1.2->-r requirements.txt (line 7)) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Jinja2>=2.10.1->flask==1.1.1->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas==0.25.3->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from Werkzeug>=0.15->flask==1.1.1->-r requirements.txt (line 6)) (0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->pytest==5.1.2->-r requirements.txt (line 7)) (2.4.7)\n",
      "Installing collected packages: ppxgboost\n",
      "  Attempting uninstall: ppxgboost\n",
      "    Found existing installation: ppxgboost 0.0.1\n",
      "    Uninstalling ppxgboost-0.0.1:\n",
      "      Successfully uninstalled ppxgboost-0.0.1\n",
      "  Running setup.py develop for ppxgboost\n",
      "Successfully installed ppxgboost-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/awslabs/privacy-preserving-xgboost-inference.git\n",
    "%cd privacy-preserving-xgboost-inference\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bfdfa8",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94c378",
   "metadata": {},
   "source": [
    "( Run <code>jupyter notebook</code> under the project directory )\n",
    "\n",
    "# XGBoost for Iris Dataset\n",
    "\n",
    "We use this example to demenstrate how to use ppxgboost for encypting an xgboost model for multi-class\n",
    " prediction. We directly use the iris data from Sklearn, but one\n",
    " can go to https://archive.ics.uci.edu/ml/datasets/iris to download the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c2e640",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('third-party')\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from secrets import token_bytes\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ppxgboost import BoosterParser as boostparser\n",
    "from ppxgboost import PPBooster as ppbooster\n",
    "from ppxgboost.PPBooster import MetaData\n",
    "from ppxgboost.PPKey import PPBoostKey\n",
    "from ope.pyope.ope import OPE\n",
    "from ppxgboost import PaillierAPI as paillier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed9d70f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bc = load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "\n",
    "# Pre-assign the column name first.\n",
    "# the default feature name from the xgboost -- iris have 4 columns\n",
    "feature_names = bc.feature_names\n",
    "X = pd.DataFrame(X, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc7634",
   "metadata": {},
   "source": [
    "### Remove Spaces in Column Names\n",
    "\n",
    "Since the `BoosterParser` in ppxgboost cannot parser column name with space in it, we have to remove the space for the parser to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eaa84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = [c.replace(\" \", \"\") for c in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e907e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanradius</th>\n",
       "      <th>meantexture</th>\n",
       "      <th>meanperimeter</th>\n",
       "      <th>meanarea</th>\n",
       "      <th>meansmoothness</th>\n",
       "      <th>meancompactness</th>\n",
       "      <th>meanconcavity</th>\n",
       "      <th>meanconcavepoints</th>\n",
       "      <th>meansymmetry</th>\n",
       "      <th>meanfractaldimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worstradius</th>\n",
       "      <th>worsttexture</th>\n",
       "      <th>worstperimeter</th>\n",
       "      <th>worstarea</th>\n",
       "      <th>worstsmoothness</th>\n",
       "      <th>worstcompactness</th>\n",
       "      <th>worstconcavity</th>\n",
       "      <th>worstconcavepoints</th>\n",
       "      <th>worstsymmetry</th>\n",
       "      <th>worstfractaldimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanradius  meantexture  meanperimeter  meanarea  meansmoothness  \\\n",
       "0       17.99        10.38         122.80    1001.0         0.11840   \n",
       "1       20.57        17.77         132.90    1326.0         0.08474   \n",
       "2       19.69        21.25         130.00    1203.0         0.10960   \n",
       "3       11.42        20.38          77.58     386.1         0.14250   \n",
       "4       20.29        14.34         135.10    1297.0         0.10030   \n",
       "\n",
       "   meancompactness  meanconcavity  meanconcavepoints  meansymmetry  \\\n",
       "0          0.27760         0.3001            0.14710        0.2419   \n",
       "1          0.07864         0.0869            0.07017        0.1812   \n",
       "2          0.15990         0.1974            0.12790        0.2069   \n",
       "3          0.28390         0.2414            0.10520        0.2597   \n",
       "4          0.13280         0.1980            0.10430        0.1809   \n",
       "\n",
       "   meanfractaldimension  ...  worstradius  worsttexture  worstperimeter  \\\n",
       "0               0.07871  ...        25.38         17.33          184.60   \n",
       "1               0.05667  ...        24.99         23.41          158.80   \n",
       "2               0.05999  ...        23.57         25.53          152.50   \n",
       "3               0.09744  ...        14.91         26.50           98.87   \n",
       "4               0.05883  ...        22.54         16.67          152.20   \n",
       "\n",
       "   worstarea  worstsmoothness  worstcompactness  worstconcavity  \\\n",
       "0     2019.0           0.1622            0.6656          0.7119   \n",
       "1     1956.0           0.1238            0.1866          0.2416   \n",
       "2     1709.0           0.1444            0.4245          0.4504   \n",
       "3      567.7           0.2098            0.8663          0.6869   \n",
       "4     1575.0           0.1374            0.2050          0.4000   \n",
       "\n",
       "   worstconcavepoints  worstsymmetry  worstfractaldimension  \n",
       "0              0.2654         0.4601                0.11890  \n",
       "1              0.1860         0.2750                0.08902  \n",
       "2              0.2430         0.3613                0.08758  \n",
       "3              0.2575         0.6638                0.17300  \n",
       "4              0.1625         0.2364                0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83a37758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8274b6b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "test_input_vector = pd.DataFrame(X_test, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abde5849",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train a xgboost model \n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "params = {'eta': 0.1}\n",
    "model = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "# predict using the plaintext prediction\n",
    "plaintext_predict = model.predict(xgb.DMatrix(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b668dcce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramaeter Extraction Time:  0.007462263107299805\n"
     ]
    }
   ],
   "source": [
    "# 1. parsing to internal tree data structure, and output feature set\n",
    "start = time.time()\n",
    "min_max = boostparser.training_dataset_parser(X_test)\n",
    "enc_tree, feature_set, min_max = boostparser.model_to_trees(model, min_max)\n",
    "end = time.time()\n",
    "print(\"Paramaeter Extraction Time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aaa87a1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypter and Key Generation:  0.08191537857055664\n"
     ]
    }
   ],
   "source": [
    "# 2. Set up encryption materials.\n",
    "start = time.time()\n",
    "prf_key = token_bytes(16)\n",
    "public_key, private_key = paillier.he_key_gen()\n",
    "encrypter = OPE(token_bytes(16))\n",
    "ppBoostKey = PPBoostKey(public_key, prf_key, encrypter)\n",
    "end = time.time()\n",
    "print(\"Encrypter and Key Generation: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648ca7e0",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Encrypted Tree:  3.721642255783081\n"
     ]
    }
   ],
   "source": [
    "# 3. process the tree into enc_tree\n",
    "start = time.time()\n",
    "ppbooster.enc_xgboost_model(ppBoostKey, enc_tree, MetaData(min_max))\n",
    "end = time.time()\n",
    "print(\"Create Encrypted Tree: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57135863",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Encrypted Test Data:  14.867348670959473\n"
     ]
    }
   ],
   "source": [
    "# 4. Encrypts the input vector for prediction (using prf_key_hash and ope-encrypter) based on the feature set.\n",
    "start = time.time()\n",
    "ppbooster.enc_input_vector(prf_key, encrypter, feature_set, X_test, MetaData(min_max))\n",
    "end = time.time()\n",
    "print(\"Create Encrypted Test Data: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88ec25ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP Predict Elapsed Time:  0.1878814697265625\n"
     ]
    }
   ],
   "source": [
    "# 5. privacy-preserving evaluation.\n",
    "start = time.time()\n",
    "values = ppbooster.predict_binary(enc_tree, X_test)\n",
    "end = time.time()\n",
    "print(\"PP Predict Elapsed Time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b5a9092",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decrypt Prediction Result Time:  0.44504714012145996\n"
     ]
    }
   ],
   "source": [
    "# 6. decryption\n",
    "start = time.time()\n",
    "decryptions = []\n",
    "for c in values:\n",
    "    decryptions.append(paillier.decrypt(private_key, c))\n",
    "decryptions = np.array([round(x, 7) for x in decryptions])\n",
    "end = time.time()\n",
    "print(\"Decrypt Prediction Result Time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb5e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the predicted values are same (the ppxgboost might not produce same values\n",
    "#                                   as the plaintext value due to precision)\n",
    "assert len(plaintext_predict) == len(decryptions)\n",
    "for i in range(len(plaintext_predict)):\n",
    "    assert abs(plaintext_predict[i] - decryptions[i]) < 0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c29fcc",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "Remove the ppxgboost folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21a40a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/myAWSStudyBlog/privacy-preserving-ml/ppxgboost\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!rm -rf privacy-preserving-xgboost-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca5073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
